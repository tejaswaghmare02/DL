{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Forward pass with matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data :\n",
      " [[0.5 0.3]\n",
      " [0.2 0.7]\n",
      " [0.8 0.9]]\n",
      "Weighted Sum :\n",
      " [[0.56]\n",
      " [0.4 ]\n",
      " [0.92]]\n",
      "Output :\n",
      " [[0.63645254]\n",
      " [0.59868766]\n",
      " [0.71504211]]\n",
      "Loss :\n",
      " [[0.04405559]\n",
      " [0.11947564]\n",
      " [0.027067  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def activation(z):\n",
    "  return 1/(1+np.exp(-z))\n",
    "\n",
    "def loss_function(target,output):                #Mean Squared Error\n",
    "  return (1/len(target))*np.square(target-output)\n",
    "\n",
    "def forwardpass(x,weights,bias):\n",
    "  weighted_sum=np.dot(x,weights)+bias\n",
    "  print(\"Weighted Sum :\\n\",weighted_sum)\n",
    "  output=activation(weighted_sum)\n",
    "  return output\n",
    "\n",
    "#input data\n",
    "x=np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
    "\n",
    "#weights\n",
    "weights=np.array([[0.8], [0.2]])\n",
    "\n",
    "#targets\n",
    "targets=np.array([[1], [0], [1]])\n",
    "\n",
    "#bias\n",
    "bias=np.array([0.1])\n",
    "\n",
    "print(\"Input Data :\\n\",x)\n",
    "\n",
    "output=forwardpass(x,weights,bias)\n",
    "loss=loss_function(targets,output)\n",
    "\n",
    "print(\"Output :\\n\",output)\n",
    "print(\"Loss :\\n\",loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward pass with hidden layer (matrix multiplication) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Sum from input layer :\n",
      " [[0.62 0.87]\n",
      " [0.54 1.17]\n",
      " [1.1  1.47]]\n",
      "Weighted Sum from hidden layer :\n",
      " [[0.88838755]\n",
      " [0.92374524]\n",
      " [0.9942182 ]]\n",
      "Input Data :\n",
      " [[0.5 0.3]\n",
      " [0.2 0.7]\n",
      " [0.8 0.9]]\n",
      "Output :\n",
      " [[0.70855731]\n",
      " [0.71580461]\n",
      " [0.72992029]]\n",
      "Loss :\n",
      " [[0.02831295]\n",
      " [0.17079208]\n",
      " [0.02431435]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def forwardpass(x,w1,w2,b1,b2):\n",
    "  #input to hidden layer\n",
    "  weighted_sum1=np.dot(x,w1)+b1\n",
    "  print(\"Weighted Sum from input layer :\\n\",weighted_sum1)\n",
    "  h_in=activation(weighted_sum1)\n",
    "  #hidden to output layer\n",
    "  weighted_sum2=np.dot(h_in,w2)+b2\n",
    "  print(\"Weighted Sum from hidden layer :\\n\",weighted_sum2)\n",
    "  h_out=activation(weighted_sum2)\n",
    "  return h_out\n",
    "\n",
    "#input data\n",
    "x=np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
    "\n",
    "#targets\n",
    "targets=np.array([[1], [0], [1]])\n",
    "\n",
    "# Weights and biases for the input layer to hidden layer\n",
    "w1= np.array([[0.8, 0.2], [0.4, 0.9]])\n",
    "b1 = np.array([0.1, 0.5])\n",
    "\n",
    "# Weights and bias for the hidden layer to output layer\n",
    "w2 = np.array([[0.3], [0.7]])\n",
    "b2= np.array([0.2])\n",
    "\n",
    "final_output=forwardpass(x,w1,w2,b1,b2)\n",
    "loss=loss_function(targets,final_output)\n",
    "\n",
    "print(\"Input Data :\\n\",x)\n",
    "print(\"Output :\\n\",final_output)\n",
    "print(\"Loss :\\n\",loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward pass with matrix multiplication with Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.0826\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0825\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0823\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0822\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0821\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0819\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0818\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0817\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0815\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0814\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0813\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0811\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0810\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0809\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0808\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0806\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0805\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0804\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0802\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0801\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0800\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0799\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0798\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0796\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0795\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0794\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0793\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0791\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0790\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0789\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0788\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0787\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0786\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0784\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0783\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0782\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0781\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0780\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0779\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0778\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0776\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0775\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0774\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0773\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0772\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0771\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0770\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0769\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0768\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0767\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0766\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0765\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0764\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0763\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0762\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0761\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0760\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0759\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0758\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0757\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0756\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0755\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0754\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0753\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0752\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0751\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0750\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0749\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0748\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0747\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0747\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0746\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0745\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0744\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0743\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0742\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0741\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0740\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0740\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0739\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0738\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0737\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0736\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0736\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0735\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0734\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0733\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0732\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0732\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0731\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0730\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0729\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0728\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0728\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0727\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0726\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0726\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0725\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0724\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0723\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "\n",
      "Input Data :\n",
      " [[0.5 0.3]\n",
      " [0.2 0.7]\n",
      " [0.8 0.9]]\n",
      "\n",
      "Output Data :\n",
      " [[0.4714214]\n",
      " [0.5969051]\n",
      " [0.5107312]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def forward_pass(x, epochs=100):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, activation='sigmoid', input_dim=2))  # Input to output\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x, x, epochs=epochs)\n",
    "    output = model.predict(x)\n",
    "    return output\n",
    "\n",
    "# Input data\n",
    "x = np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
    "\n",
    "# Output data\n",
    "output = forward_pass(x)\n",
    "\n",
    "print(\"\\nInput Data :\\n\", x)\n",
    "print(\"\\nOutput Data :\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward passes with hidden layer (matrix multiplication) with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0694\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0694\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0693\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0693\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0692\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0692\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0692\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0691\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0691\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0690\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0690\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0689\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0689\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0688\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0688\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0688\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0687\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0687\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0686\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0686\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0686\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0685\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0685\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0684\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0684\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0684\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0683\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0683\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0683\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0682\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0682\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0681\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0681\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0681\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0680\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0680\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0680\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0679\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0679\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0679\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0678\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0678\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0678\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0677\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0677\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0677\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0677\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0676\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0676\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0676\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0675\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0675\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0675\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0674\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0674\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0674\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0674\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0673\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0673\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0673\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0673\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0672\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0672\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0672\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0671\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0671\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0671\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0671\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0670\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0670\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0670\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0670\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0669\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0669\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0669\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0669\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0668\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0668\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0668\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0668\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0667\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0667\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0667\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0667\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0666\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0666\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0666\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0666\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0666\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0665\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0665\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0665\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0665\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0664\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0664\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0664\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0664\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0663\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0663\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0663\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "\n",
      "Input Data :\n",
      " [[0.5 0.3]\n",
      " [0.2 0.7]\n",
      " [0.8 0.9]]\n",
      "\n",
      "Output Data :\n",
      " [[0.5970554 ]\n",
      " [0.5421659 ]\n",
      " [0.57338387]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def forward_pass(x, epochs=100):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=2, activation='sigmoid', input_dim=2))  # Input to hidden\n",
    "    model.add(Dense(units=1, activation='sigmoid'))  # Hidden to output\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x, x, epochs=epochs)\n",
    "    output = model.predict(x)\n",
    "    return output\n",
    "\n",
    "# Input data\n",
    "x = np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
    "\n",
    "# Output data\n",
    "output = forward_pass(x) \n",
    "\n",
    "print(\"\\nInput Data :\\n\", x)\n",
    "print(\"\\nOutput Data :\\n\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
